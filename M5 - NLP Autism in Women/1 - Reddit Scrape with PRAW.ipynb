{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "475b1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04eb9d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup reddit client\n",
    "user_agent = \"Scraper 1.0 by /u/ericajstevenson\"\n",
    "reddit = praw.Reddit(\n",
    "    client_id = \"insert_client_id\",\n",
    "    client_secret = \"insert_client_secret\",\n",
    "    user_agent = user_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5695f0e",
   "metadata": {},
   "source": [
    "### aspergirls subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e16ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the content of user posts and run Reddit API\n",
    "# To capture as many posts as possible, the scrape is run for each of the reddit categories (hot, new, rising, top)\n",
    "title = []\n",
    "ID = []\n",
    "author = []\n",
    "created_utc = []\n",
    "score = []\n",
    "upvote_ratio = []\n",
    "url = []\n",
    "selftext = []\n",
    "name = []\n",
    "num_comments = []\n",
    "for submission in reddit.subreddit('aspergirls').hot(limit=1000):\n",
    "    title.append(submission.title)\n",
    "    ID.append(submission.id)\n",
    "    author.append(submission.author)\n",
    "    created_utc.append(submission.created_utc)\n",
    "    score.append(submission.score)\n",
    "    upvote_ratio.append(submission.upvote_ratio)\n",
    "    url.append(submission.url)\n",
    "    selftext.append(submission.selftext)\n",
    "    name.append(submission.name)\n",
    "    num_comments.append(submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb21b36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(962, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from zipped lists. Pickle for later.\n",
    "zippedList =  list(zip(ID,title,author,created_utc,score,upvote_ratio,selftext,name,num_comments)) \n",
    "df = pd.DataFrame(zippedList,\n",
    "                     columns = ['ID','title','author','created_utc','score','upvote_ratio','selftext','name','num_comments']) \n",
    "df.to_pickle('aspergirls_hot_0516.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f125ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>selftext</th>\n",
       "      <th>name</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>ulvx2r</td>\n",
       "      <td>I made this “Embrace Neurodiversity” sticker t...</td>\n",
       "      <td>Kathyschaotic</td>\n",
       "      <td>1.652116e+09</td>\n",
       "      <td>317</td>\n",
       "      <td>0.98</td>\n",
       "      <td></td>\n",
       "      <td>t3_ulvx2r</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>uhg6fn</td>\n",
       "      <td>I’m so tired of being disabled. How do I confr...</td>\n",
       "      <td>Grace-and-Maya</td>\n",
       "      <td>1.651585e+09</td>\n",
       "      <td>39</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Outside of autism I have CPTSD, long term depr...</td>\n",
       "      <td>t3_uhg6fn</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>ucivae</td>\n",
       "      <td>Sensory issues, Chub rub and wedding help</td>\n",
       "      <td>blazingsunbeams</td>\n",
       "      <td>1.650997e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Hi folks,\\n\\nPosting intentionally here becaus...</td>\n",
       "      <td>t3_ucivae</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>uiqei2</td>\n",
       "      <td>I am mentally and physically exhausted</td>\n",
       "      <td>myartpopera</td>\n",
       "      <td>1.651729e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Having trouble in dealing with the transition ...</td>\n",
       "      <td>t3_uiqei2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>umlzsv</td>\n",
       "      <td>one joke, and ill obsess over it for days.</td>\n",
       "      <td>None</td>\n",
       "      <td>1.652198e+09</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>If someone makes a joke about me, anything at ...</td>\n",
       "      <td>t3_umlzsv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>u4sfqm</td>\n",
       "      <td>How to handle overwhelm after just waking up?</td>\n",
       "      <td>Paulakris</td>\n",
       "      <td>1.650094e+09</td>\n",
       "      <td>18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Often times when I wake up in the morning I am...</td>\n",
       "      <td>t3_u4sfqm</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>u6ykzt</td>\n",
       "      <td>Beware: Man using this subreddit to hit on women</td>\n",
       "      <td>HelenAngel</td>\n",
       "      <td>1.650350e+09</td>\n",
       "      <td>428</td>\n",
       "      <td>1.00</td>\n",
       "      <td>A Reddit user who goes by u/rumpwell6 commente...</td>\n",
       "      <td>t3_u6ykzt</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>una8p3</td>\n",
       "      <td>Autism and OCD Question</td>\n",
       "      <td>lexisplenda</td>\n",
       "      <td>1.652277e+09</td>\n",
       "      <td>14</td>\n",
       "      <td>0.95</td>\n",
       "      <td>I was wondering if anyone here had experience ...</td>\n",
       "      <td>t3_una8p3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>ud6pff</td>\n",
       "      <td>Adjustments that have helped you avoid/mitigat...</td>\n",
       "      <td>Paulakris</td>\n",
       "      <td>1.651075e+09</td>\n",
       "      <td>71</td>\n",
       "      <td>0.99</td>\n",
       "      <td>So I remember someone recently posting about t...</td>\n",
       "      <td>t3_ud6pff</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>uhlt6v</td>\n",
       "      <td>do you take medication for meltdowns/panic att...</td>\n",
       "      <td>radio-duck</td>\n",
       "      <td>1.651601e+09</td>\n",
       "      <td>5</td>\n",
       "      <td>0.86</td>\n",
       "      <td>Hi,\\n\\nI (25F diagnosed with autism, persisten...</td>\n",
       "      <td>t3_uhlt6v</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                              title  \\\n",
       "203  ulvx2r  I made this “Embrace Neurodiversity” sticker t...   \n",
       "438  uhg6fn  I’m so tired of being disabled. How do I confr...   \n",
       "663  ucivae          Sensory issues, Chub rub and wedding help   \n",
       "400  uiqei2             I am mentally and physically exhausted   \n",
       "196  umlzsv         one joke, and ill obsess over it for days.   \n",
       "945  u4sfqm      How to handle overwhelm after just waking up?   \n",
       "854  u6ykzt   Beware: Man using this subreddit to hit on women   \n",
       "167  una8p3                            Autism and OCD Question   \n",
       "613  ud6pff  Adjustments that have helped you avoid/mitigat...   \n",
       "448  uhlt6v  do you take medication for meltdowns/panic att...   \n",
       "\n",
       "              author   created_utc  score  upvote_ratio  \\\n",
       "203    Kathyschaotic  1.652116e+09    317          0.98   \n",
       "438   Grace-and-Maya  1.651585e+09     39          1.00   \n",
       "663  blazingsunbeams  1.650997e+09      9          1.00   \n",
       "400      myartpopera  1.651729e+09      4          1.00   \n",
       "196             None  1.652198e+09     10          1.00   \n",
       "945        Paulakris  1.650094e+09     18          1.00   \n",
       "854       HelenAngel  1.650350e+09    428          1.00   \n",
       "167      lexisplenda  1.652277e+09     14          0.95   \n",
       "613        Paulakris  1.651075e+09     71          0.99   \n",
       "448       radio-duck  1.651601e+09      5          0.86   \n",
       "\n",
       "                                              selftext       name  \\\n",
       "203                                                     t3_ulvx2r   \n",
       "438  Outside of autism I have CPTSD, long term depr...  t3_uhg6fn   \n",
       "663  Hi folks,\\n\\nPosting intentionally here becaus...  t3_ucivae   \n",
       "400  Having trouble in dealing with the transition ...  t3_uiqei2   \n",
       "196  If someone makes a joke about me, anything at ...  t3_umlzsv   \n",
       "945  Often times when I wake up in the morning I am...  t3_u4sfqm   \n",
       "854  A Reddit user who goes by u/rumpwell6 commente...  t3_u6ykzt   \n",
       "167  I was wondering if anyone here had experience ...  t3_una8p3   \n",
       "613  So I remember someone recently posting about t...  t3_ud6pff   \n",
       "448  Hi,\\n\\nI (25F diagnosed with autism, persisten...  t3_uhlt6v   \n",
       "\n",
       "     num_comments  \n",
       "203            13  \n",
       "438            12  \n",
       "663            22  \n",
       "400             3  \n",
       "196             1  \n",
       "945            13  \n",
       "854            42  \n",
       "167             4  \n",
       "613            56  \n",
       "448             6  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76d4f0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the content of user posts and run Reddit API\n",
    "# To capture as many posts as possible, the scrape is run for each of the reddit categories (hot, new, rising, top)\n",
    "title = []\n",
    "ID = []\n",
    "author = []\n",
    "created_utc = []\n",
    "score = []\n",
    "upvote_ratio = []\n",
    "url = []\n",
    "selftext = []\n",
    "name = []\n",
    "num_comments = []\n",
    "for submission in reddit.subreddit('aspergirls').new(limit=1000): \n",
    "    title.append(submission.title)\n",
    "    ID.append(submission.id)\n",
    "    author.append(submission.author)\n",
    "    created_utc.append(submission.created_utc)\n",
    "    score.append(submission.score)\n",
    "    upvote_ratio.append(submission.upvote_ratio)\n",
    "    url.append(submission.url)\n",
    "    selftext.append(submission.selftext)\n",
    "    name.append(submission.name)\n",
    "    num_comments.append(submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "739aa533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(995, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from zipped lists. Pickle for later.\n",
    "zippedList =  list(zip(ID,title,author,created_utc,score,upvote_ratio,selftext,name,num_comments)) \n",
    "df = pd.DataFrame(zippedList,\n",
    "                     columns = ['ID','title','author','created_utc','score','upvote_ratio','selftext','name','num_comments']) \n",
    "df.to_pickle('aspergirls_new_0516.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d598b76e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8813bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the content of user posts and run Reddit API\n",
    "# To capture as many posts as possible, the scrape is run for each of the reddit categories (hot, new, rising, top)\n",
    "title = []\n",
    "ID = []\n",
    "author = []\n",
    "created_utc = []\n",
    "score = []\n",
    "upvote_ratio = []\n",
    "url = []\n",
    "selftext = []\n",
    "name = []\n",
    "num_comments = []\n",
    "for submission in reddit.subreddit('aspergirls').rising(limit=1000):\n",
    "    title.append(submission.title)\n",
    "    ID.append(submission.id)\n",
    "    author.append(submission.author)\n",
    "    created_utc.append(submission.created_utc)\n",
    "    score.append(submission.score)\n",
    "    upvote_ratio.append(submission.upvote_ratio)\n",
    "    url.append(submission.url)\n",
    "    selftext.append(submission.selftext)\n",
    "    name.append(submission.name)\n",
    "    num_comments.append(submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b224c916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from zipped lists. Pickle for later.\n",
    "zippedList =  list(zip(ID,title,author,created_utc,score,upvote_ratio,selftext,name,num_comments)) \n",
    "df = pd.DataFrame(zippedList,\n",
    "                     columns = ['ID','title','author','created_utc','score','upvote_ratio','selftext','name','num_comments']) \n",
    "df.to_pickle('aspergirls_rising_0516.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fb647c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1baf6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the content of user posts and run Reddit API\n",
    "# To capture as many posts as possible, the scrape is run for each of the reddit categories (hot, new, rising, top)\n",
    "title = []\n",
    "ID = []\n",
    "author = []\n",
    "created_utc = []\n",
    "score = []\n",
    "upvote_ratio = []\n",
    "url = []\n",
    "selftext = []\n",
    "name = []\n",
    "num_comments = []\n",
    "for submission in reddit.subreddit('aspergirls').top(limit=1000): \n",
    "    title.append(submission.title)\n",
    "    ID.append(submission.id)\n",
    "    author.append(submission.author)\n",
    "    created_utc.append(submission.created_utc)\n",
    "    score.append(submission.score)\n",
    "    upvote_ratio.append(submission.upvote_ratio)\n",
    "    url.append(submission.url)\n",
    "    selftext.append(submission.selftext)\n",
    "    name.append(submission.name)\n",
    "    num_comments.append(submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b658555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from zipped lists. Pickle for later.\n",
    "zippedList =  list(zip(ID,title,author,created_utc,score,upvote_ratio,selftext,name,num_comments)) \n",
    "df = pd.DataFrame(zippedList,\n",
    "                     columns = ['ID','title','author','created_utc','score','upvote_ratio','selftext','name','num_comments']) \n",
    "df.to_pickle('aspergirls_top_0516.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5614cfbd",
   "metadata": {},
   "source": [
    "### AutismInWomen subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb8d69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the content of user posts and run Reddit API\n",
    "# To capture as many posts as possible, the scrape is run for each of the reddit categories (hot, new, rising, top)\n",
    "title = []\n",
    "ID = []\n",
    "author = []\n",
    "created_utc = []\n",
    "score = []\n",
    "upvote_ratio = []\n",
    "url = []\n",
    "selftext = []\n",
    "name = []\n",
    "num_comments = []\n",
    "for submission in reddit.subreddit('AutismInWomen').hot(limit=1000): \n",
    "    title.append(submission.title)\n",
    "    ID.append(submission.id)\n",
    "    author.append(submission.author)\n",
    "    created_utc.append(submission.created_utc)\n",
    "    score.append(submission.score)\n",
    "    upvote_ratio.append(submission.upvote_ratio)\n",
    "    url.append(submission.url)\n",
    "    selftext.append(submission.selftext)\n",
    "    name.append(submission.name)\n",
    "    num_comments.append(submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b62f93c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(936, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from zipped lists. Pickle for later.\n",
    "zippedList =  list(zip(ID,title,author,created_utc,score,upvote_ratio,selftext,name,num_comments)) \n",
    "df = pd.DataFrame(zippedList,\n",
    "                     columns = ['ID','title','author','created_utc','score','upvote_ratio','selftext','name','num_comments']) \n",
    "df.to_pickle('AutismInWomen_hot_0516.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1b1cf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>selftext</th>\n",
       "      <th>name</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>udayqj</td>\n",
       "      <td>I'm so grateful for the neurodivergent community.</td>\n",
       "      <td>TechnicalCandle9343</td>\n",
       "      <td>1.651086e+09</td>\n",
       "      <td>363</td>\n",
       "      <td>0.99</td>\n",
       "      <td>Neurodiversity saved my life, I would have ser...</td>\n",
       "      <td>t3_udayqj</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>unv51e</td>\n",
       "      <td>Anyone else find writing certain letters of th...</td>\n",
       "      <td>ljb_duds</td>\n",
       "      <td>1.652339e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>0.83</td>\n",
       "      <td>This is such a random question but I got high ...</td>\n",
       "      <td>t3_unv51e</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>ukzsmk</td>\n",
       "      <td>Did anyone else get lower test scores?</td>\n",
       "      <td>Brizbizz22</td>\n",
       "      <td>1.652010e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>0.63</td>\n",
       "      <td>Hey guys, I’ve recently begun my journey into ...</td>\n",
       "      <td>t3_ukzsmk</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>uj0rc3</td>\n",
       "      <td>autism and gender identity</td>\n",
       "      <td>Groundbreaking-cut27</td>\n",
       "      <td>1.651767e+09</td>\n",
       "      <td>6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>What I have noticed is alot of autistic people...</td>\n",
       "      <td>t3_uj0rc3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>ucio70</td>\n",
       "      <td>Anyone else feel the need to be perfect?</td>\n",
       "      <td>unic0rn_beard</td>\n",
       "      <td>1.650996e+09</td>\n",
       "      <td>124</td>\n",
       "      <td>0.98</td>\n",
       "      <td>I've noticed recently that the reason why I do...</td>\n",
       "      <td>t3_ucio70</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>um9g5r</td>\n",
       "      <td>“I know just how your little ASD brain works”</td>\n",
       "      <td>Euonym_</td>\n",
       "      <td>1.652154e+09</td>\n",
       "      <td>322</td>\n",
       "      <td>0.99</td>\n",
       "      <td>A doctor just said this to me as she has a son...</td>\n",
       "      <td>t3_um9g5r</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>ueip95</td>\n",
       "      <td>Anyone else have this stim?</td>\n",
       "      <td>violaqween</td>\n",
       "      <td>1.651227e+09</td>\n",
       "      <td>10</td>\n",
       "      <td>0.92</td>\n",
       "      <td>I have really sensitive fingertips and when I’...</td>\n",
       "      <td>t3_ueip95</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>ulk8d7</td>\n",
       "      <td>Does anyone feel like there are way more and d...</td>\n",
       "      <td>Onion1995</td>\n",
       "      <td>1.652075e+09</td>\n",
       "      <td>52</td>\n",
       "      <td>0.96</td>\n",
       "      <td>I feel like that is the case. We are always so...</td>\n",
       "      <td>t3_ulk8d7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>umzdzz</td>\n",
       "      <td>watching a science related docu with 'emotiona...</td>\n",
       "      <td>SeededPhoenix</td>\n",
       "      <td>1.652236e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>0.63</td>\n",
       "      <td>Recently self diagnosed and I'm noticing mysel...</td>\n",
       "      <td>t3_umzdzz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>unqz9l</td>\n",
       "      <td>Does anyone else find that you're the most cap...</td>\n",
       "      <td>Hoihe</td>\n",
       "      <td>1.652324e+09</td>\n",
       "      <td>218</td>\n",
       "      <td>1.00</td>\n",
       "      <td>It's the only way I managed to save WFH, and I...</td>\n",
       "      <td>t3_unqz9l</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                              title  \\\n",
       "839  udayqj  I'm so grateful for the neurodivergent community.   \n",
       "208  unv51e  Anyone else find writing certain letters of th...   \n",
       "404  ukzsmk             Did anyone else get lower test scores?   \n",
       "509  uj0rc3                         autism and gender identity   \n",
       "894  ucio70           Anyone else feel the need to be perfect?   \n",
       "274  um9g5r      “I know just how your little ASD brain works”   \n",
       "799  ueip95                        Anyone else have this stim?   \n",
       "341  ulk8d7  Does anyone feel like there are way more and d...   \n",
       "282  umzdzz  watching a science related docu with 'emotiona...   \n",
       "165  unqz9l  Does anyone else find that you're the most cap...   \n",
       "\n",
       "                   author   created_utc  score  upvote_ratio  \\\n",
       "839   TechnicalCandle9343  1.651086e+09    363          0.99   \n",
       "208              ljb_duds  1.652339e+09      4          0.83   \n",
       "404            Brizbizz22  1.652010e+09      2          0.63   \n",
       "509  Groundbreaking-cut27  1.651767e+09      6          0.80   \n",
       "894         unic0rn_beard  1.650996e+09    124          0.98   \n",
       "274               Euonym_  1.652154e+09    322          0.99   \n",
       "799            violaqween  1.651227e+09     10          0.92   \n",
       "341             Onion1995  1.652075e+09     52          0.96   \n",
       "282         SeededPhoenix  1.652236e+09      2          0.63   \n",
       "165                 Hoihe  1.652324e+09    218          1.00   \n",
       "\n",
       "                                              selftext       name  \\\n",
       "839  Neurodiversity saved my life, I would have ser...  t3_udayqj   \n",
       "208  This is such a random question but I got high ...  t3_unv51e   \n",
       "404  Hey guys, I’ve recently begun my journey into ...  t3_ukzsmk   \n",
       "509  What I have noticed is alot of autistic people...  t3_uj0rc3   \n",
       "894  I've noticed recently that the reason why I do...  t3_ucio70   \n",
       "274  A doctor just said this to me as she has a son...  t3_um9g5r   \n",
       "799  I have really sensitive fingertips and when I’...  t3_ueip95   \n",
       "341  I feel like that is the case. We are always so...  t3_ulk8d7   \n",
       "282  Recently self diagnosed and I'm noticing mysel...  t3_umzdzz   \n",
       "165  It's the only way I managed to save WFH, and I...  t3_unqz9l   \n",
       "\n",
       "     num_comments  \n",
       "839            26  \n",
       "208            17  \n",
       "404             8  \n",
       "509             6  \n",
       "894            35  \n",
       "274            69  \n",
       "799            12  \n",
       "341             6  \n",
       "282             0  \n",
       "165            33  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90473b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the content of user posts and run Reddit API\n",
    "# To capture as many posts as possible, the scrape is run for each of the reddit categories (hot, new, rising, top)\n",
    "title = []\n",
    "ID = []\n",
    "author = []\n",
    "created_utc = []\n",
    "score = []\n",
    "upvote_ratio = []\n",
    "url = []\n",
    "selftext = []\n",
    "name = []\n",
    "num_comments = []\n",
    "for submission in reddit.subreddit('AutismInWomen').new(limit=1000): \n",
    "    title.append(submission.title)\n",
    "    ID.append(submission.id)\n",
    "    author.append(submission.author)\n",
    "    created_utc.append(submission.created_utc)\n",
    "    score.append(submission.score)\n",
    "    upvote_ratio.append(submission.upvote_ratio)\n",
    "    url.append(submission.url)\n",
    "    selftext.append(submission.selftext)\n",
    "    name.append(submission.name)\n",
    "    num_comments.append(submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f59810d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(996, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from zipped lists. Pickle for later.\n",
    "zippedList =  list(zip(ID,title,author,created_utc,score,upvote_ratio,selftext,name,num_comments)) \n",
    "df = pd.DataFrame(zippedList,\n",
    "                     columns = ['ID','title','author','created_utc','score','upvote_ratio','selftext','name','num_comments']) \n",
    "df.to_pickle('AutismInWomen_new_0516.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee1bd55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfa43039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the content of user posts and run Reddit API\n",
    "# To capture as many posts as possible, the scrape is run for each of the reddit categories (hot, new, rising, top)\n",
    "title = []\n",
    "ID = []\n",
    "author = []\n",
    "created_utc = []\n",
    "score = []\n",
    "upvote_ratio = []\n",
    "url = []\n",
    "selftext = []\n",
    "name = []\n",
    "num_comments = []\n",
    "for submission in reddit.subreddit('AutismInWomen').rising(limit=1000): \n",
    "    title.append(submission.title)\n",
    "    ID.append(submission.id)\n",
    "    author.append(submission.author)\n",
    "    created_utc.append(submission.created_utc)\n",
    "    score.append(submission.score)\n",
    "    upvote_ratio.append(submission.upvote_ratio)\n",
    "    url.append(submission.url)\n",
    "    selftext.append(submission.selftext)\n",
    "    name.append(submission.name)\n",
    "    num_comments.append(submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d207d8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 9)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from zipped lists. Pickle for later.\n",
    "zippedList =  list(zip(ID,title,author,created_utc,score,upvote_ratio,selftext,name,num_comments)) \n",
    "df = pd.DataFrame(zippedList,\n",
    "                     columns = ['ID','title','author','created_utc','score','upvote_ratio','selftext','name','num_comments']) \n",
    "df.to_pickle('AutismInWomen_rising_0516.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b653248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d85b6eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the content of user posts and run Reddit API\n",
    "# To capture as many posts as possible, the scrape is run for each of the reddit categories (hot, new, rising, top)\n",
    "title = []\n",
    "ID = []\n",
    "author = []\n",
    "created_utc = []\n",
    "score = []\n",
    "upvote_ratio = []\n",
    "url = []\n",
    "selftext = []\n",
    "name = []\n",
    "num_comments = []\n",
    "for submission in reddit.subreddit('AutismInWomen').top(limit=1000): \n",
    "    title.append(submission.title)\n",
    "    ID.append(submission.id)\n",
    "    author.append(submission.author)\n",
    "    created_utc.append(submission.created_utc)\n",
    "    score.append(submission.score)\n",
    "    upvote_ratio.append(submission.upvote_ratio)\n",
    "    url.append(submission.url)\n",
    "    selftext.append(submission.selftext)\n",
    "    name.append(submission.name)\n",
    "    num_comments.append(submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c417486e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from zipped lists. Pickle for later.\n",
    "zippedList =  list(zip(ID,title,author,created_utc,score,upvote_ratio,selftext,name,num_comments)) \n",
    "df = pd.DataFrame(zippedList,\n",
    "                     columns = ['ID','title','author','created_utc','score','upvote_ratio','selftext','name','num_comments']) \n",
    "df.to_pickle('AutismInWomen_top_0516.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e09ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0114308e",
   "metadata": {},
   "source": [
    "### autism subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a4fd8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the content of user posts and run Reddit API\n",
    "# To capture as many posts as possible, the scrape is run for each of the reddit categories (hot, new, rising, top)\n",
    "title = []\n",
    "ID = []\n",
    "author = []\n",
    "created_utc = []\n",
    "score = []\n",
    "upvote_ratio = []\n",
    "url = []\n",
    "selftext = []\n",
    "name = []\n",
    "num_comments = []\n",
    "for submission in reddit.subreddit('autism').hot(limit=1000): \n",
    "    title.append(submission.title)\n",
    "    ID.append(submission.id)\n",
    "    author.append(submission.author)\n",
    "    created_utc.append(submission.created_utc)\n",
    "    score.append(submission.score)\n",
    "    upvote_ratio.append(submission.upvote_ratio)\n",
    "    url.append(submission.url)\n",
    "    selftext.append(submission.selftext)\n",
    "    name.append(submission.name)\n",
    "    num_comments.append(submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd200643",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(986, 9)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from zipped lists. Pickle for later.\n",
    "zippedList =  list(zip(ID,title,author,created_utc,score,upvote_ratio,selftext,name,num_comments)) \n",
    "df = pd.DataFrame(zippedList,\n",
    "                     columns = ['ID','title','author','created_utc','score','upvote_ratio','selftext','name','num_comments']) \n",
    "df.to_pickle('autism_hot_0516.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48f5f9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>selftext</th>\n",
       "      <th>name</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>uqv2hy</td>\n",
       "      <td>I love my cat</td>\n",
       "      <td>Shenhe_Enjoyer</td>\n",
       "      <td>1.652705e+09</td>\n",
       "      <td>12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>This is a random post but as an Autistic perso...</td>\n",
       "      <td>t3_uqv2hy</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>uozgkw</td>\n",
       "      <td>Is a disability just a more severe form of a d...</td>\n",
       "      <td>No-Job-4870</td>\n",
       "      <td>1.652470e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "      <td>I hear adhd being called a disorder and autism...</td>\n",
       "      <td>t3_uozgkw</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>upvc42</td>\n",
       "      <td>does anyone else HATE the sound of dogs barking</td>\n",
       "      <td>Exzj</td>\n",
       "      <td>1.652579e+09</td>\n",
       "      <td>20</td>\n",
       "      <td>0.88</td>\n",
       "      <td>ive had a dog in my family basically my whole ...</td>\n",
       "      <td>t3_upvc42</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>uox42m</td>\n",
       "      <td>is it wrong to treat a child as if they are au...</td>\n",
       "      <td>JSavnet</td>\n",
       "      <td>1.652464e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>Hello, really need some advice hereFirstly, th...</td>\n",
       "      <td>t3_uox42m</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>unkviu</td>\n",
       "      <td>Too Disabled To Work</td>\n",
       "      <td>YourClairyGodmother</td>\n",
       "      <td>1.652306e+09</td>\n",
       "      <td>22</td>\n",
       "      <td>0.88</td>\n",
       "      <td>I'm considered too disabled to work by the gov...</td>\n",
       "      <td>t3_unkviu</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>upm6xs</td>\n",
       "      <td>This is amazing!! Every supermarket should hav...</td>\n",
       "      <td>SawyerSauce879</td>\n",
       "      <td>1.652550e+09</td>\n",
       "      <td>15</td>\n",
       "      <td>0.83</td>\n",
       "      <td></td>\n",
       "      <td>t3_upm6xs</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>upgzr5</td>\n",
       "      <td>I hate it when I get last minute warnings abou...</td>\n",
       "      <td>Sqonch</td>\n",
       "      <td>1.652534e+09</td>\n",
       "      <td>61</td>\n",
       "      <td>0.98</td>\n",
       "      <td>Hi, Im kinda freaking out rn. My roomate (and ...</td>\n",
       "      <td>t3_upgzr5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>uoiagg</td>\n",
       "      <td>what is your personality type on the Myers Bri...</td>\n",
       "      <td>JacobPlourde</td>\n",
       "      <td>1.652411e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>I know it's not recognize in psychology but it...</td>\n",
       "      <td>t3_uoiagg</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uqi2xi</td>\n",
       "      <td>This is what neurotypical social rules sound l...</td>\n",
       "      <td>Akem0417</td>\n",
       "      <td>1.652656e+09</td>\n",
       "      <td>1438</td>\n",
       "      <td>0.99</td>\n",
       "      <td></td>\n",
       "      <td>t3_uqi2xi</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>uqyttr</td>\n",
       "      <td>Swing set</td>\n",
       "      <td>Rocky_Mntn_CreeCree</td>\n",
       "      <td>1.652716e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>I have an young adult son that calms himself b...</td>\n",
       "      <td>t3_uqyttr</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                              title  \\\n",
       "20   uqv2hy                                      I love my cat   \n",
       "642  uozgkw  Is a disability just a more severe form of a d...   \n",
       "266  upvc42    does anyone else HATE the sound of dogs barking   \n",
       "591  uox42m  is it wrong to treat a child as if they are au...   \n",
       "905  unkviu                               Too Disabled To Work   \n",
       "349  upm6xs  This is amazing!! Every supermarket should hav...   \n",
       "320  upgzr5  I hate it when I get last minute warnings abou...   \n",
       "779  uoiagg  what is your personality type on the Myers Bri...   \n",
       "4    uqi2xi  This is what neurotypical social rules sound l...   \n",
       "81   uqyttr                                          Swing set   \n",
       "\n",
       "                  author   created_utc  score  upvote_ratio  \\\n",
       "20        Shenhe_Enjoyer  1.652705e+09     12          1.00   \n",
       "642          No-Job-4870  1.652470e+09      1          0.67   \n",
       "266                 Exzj  1.652579e+09     20          0.88   \n",
       "591              JSavnet  1.652464e+09      4          0.75   \n",
       "905  YourClairyGodmother  1.652306e+09     22          0.88   \n",
       "349       SawyerSauce879  1.652550e+09     15          0.83   \n",
       "320               Sqonch  1.652534e+09     61          0.98   \n",
       "779         JacobPlourde  1.652411e+09      0          0.50   \n",
       "4               Akem0417  1.652656e+09   1438          0.99   \n",
       "81   Rocky_Mntn_CreeCree  1.652716e+09      1          1.00   \n",
       "\n",
       "                                              selftext       name  \\\n",
       "20   This is a random post but as an Autistic perso...  t3_uqv2hy   \n",
       "642  I hear adhd being called a disorder and autism...  t3_uozgkw   \n",
       "266  ive had a dog in my family basically my whole ...  t3_upvc42   \n",
       "591  Hello, really need some advice hereFirstly, th...  t3_uox42m   \n",
       "905  I'm considered too disabled to work by the gov...  t3_unkviu   \n",
       "349                                                     t3_upm6xs   \n",
       "320  Hi, Im kinda freaking out rn. My roomate (and ...  t3_upgzr5   \n",
       "779  I know it's not recognize in psychology but it...  t3_uoiagg   \n",
       "4                                                       t3_uqi2xi   \n",
       "81   I have an young adult son that calms himself b...  t3_uqyttr   \n",
       "\n",
       "     num_comments  \n",
       "20              8  \n",
       "642            14  \n",
       "266            18  \n",
       "591            10  \n",
       "905            30  \n",
       "349             1  \n",
       "320             7  \n",
       "779            39  \n",
       "4              50  \n",
       "81              2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d115ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the content of user posts and run Reddit API\n",
    "# To capture as many posts as possible, the scrape is run for each of the reddit categories (hot, new, rising, top)\n",
    "title = []\n",
    "ID = []\n",
    "author = []\n",
    "created_utc = []\n",
    "score = []\n",
    "upvote_ratio = []\n",
    "url = []\n",
    "selftext = []\n",
    "name = []\n",
    "num_comments = []\n",
    "for submission in reddit.subreddit('autism').new(limit=1000): \n",
    "    title.append(submission.title)\n",
    "    ID.append(submission.id)\n",
    "    author.append(submission.author)\n",
    "    created_utc.append(submission.created_utc)\n",
    "    score.append(submission.score)\n",
    "    upvote_ratio.append(submission.upvote_ratio)\n",
    "    url.append(submission.url)\n",
    "    selftext.append(submission.selftext)\n",
    "    name.append(submission.name)\n",
    "    num_comments.append(submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97a295eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(997, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from zipped lists. Pickle for later.\n",
    "zippedList =  list(zip(ID,title,author,created_utc,score,upvote_ratio,selftext,name,num_comments)) \n",
    "df = pd.DataFrame(zippedList,\n",
    "                     columns = ['ID','title','author','created_utc','score','upvote_ratio','selftext','name','num_comments']) \n",
    "df.to_pickle('autism_new_0516.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27371b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e41cc68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the content of user posts and run Reddit API\n",
    "# To capture as many posts as possible, the scrape is run for each of the reddit categories (hot, new, rising, top)\n",
    "title = []\n",
    "ID = []\n",
    "author = []\n",
    "created_utc = []\n",
    "score = []\n",
    "upvote_ratio = []\n",
    "url = []\n",
    "selftext = []\n",
    "name = []\n",
    "num_comments = []\n",
    "for submission in reddit.subreddit('autism').rising(limit=1000): \n",
    "    title.append(submission.title)\n",
    "    ID.append(submission.id)\n",
    "    author.append(submission.author)\n",
    "    created_utc.append(submission.created_utc)\n",
    "    score.append(submission.score)\n",
    "    upvote_ratio.append(submission.upvote_ratio)\n",
    "    url.append(submission.url)\n",
    "    selftext.append(submission.selftext)\n",
    "    name.append(submission.name)\n",
    "    num_comments.append(submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a81cdfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 9)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from zipped lists. Pickle for later.\n",
    "zippedList =  list(zip(ID,title,author,created_utc,score,upvote_ratio,selftext,name,num_comments)) \n",
    "df = pd.DataFrame(zippedList,\n",
    "                     columns = ['ID','title','author','created_utc','score','upvote_ratio','selftext','name','num_comments']) \n",
    "df.to_pickle('autism_rising_0516.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7fe455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bfbb397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the content of user posts and run Reddit API\n",
    "# To capture as many posts as possible, the scrape is run for each of the reddit categories (hot, new, rising, top)\n",
    "title = []\n",
    "ID = []\n",
    "author = []\n",
    "created_utc = []\n",
    "score = []\n",
    "upvote_ratio = []\n",
    "url = []\n",
    "selftext = []\n",
    "name = []\n",
    "num_comments = []\n",
    "for submission in reddit.subreddit('autism').top(limit=1000):\n",
    "    title.append(submission.title)\n",
    "    ID.append(submission.id)\n",
    "    author.append(submission.author)\n",
    "    created_utc.append(submission.created_utc)\n",
    "    score.append(submission.score)\n",
    "    upvote_ratio.append(submission.upvote_ratio)\n",
    "    url.append(submission.url)\n",
    "    selftext.append(submission.selftext)\n",
    "    name.append(submission.name)\n",
    "    num_comments.append(submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81391a95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 9)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from zipped lists. Pickle for later.\n",
    "zippedList =  list(zip(ID,title,author,created_utc,score,upvote_ratio,selftext,name,num_comments)) \n",
    "df = pd.DataFrame(zippedList,\n",
    "                     columns = ['ID','title','author','created_utc','score','upvote_ratio','selftext','name','num_comments']) \n",
    "df.to_pickle('autism_top_0516.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64812cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4aae6cf",
   "metadata": {},
   "source": [
    "### aspergers subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bcd31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the content of user posts and run Reddit API\n",
    "# To capture as many posts as possible, the scrape is run for each of the reddit categories (hot, new, rising, top)\n",
    "title = []\n",
    "ID = []\n",
    "author = []\n",
    "created_utc = []\n",
    "score = []\n",
    "upvote_ratio = []\n",
    "url = []\n",
    "selftext = []\n",
    "name = []\n",
    "num_comments = []\n",
    "for submission in reddit.subreddit('aspergers').hot(limit=1000):\n",
    "    title.append(submission.title)\n",
    "    ID.append(submission.id)\n",
    "    author.append(submission.author)\n",
    "    created_utc.append(submission.created_utc)\n",
    "    score.append(submission.score)\n",
    "    upvote_ratio.append(submission.upvote_ratio)\n",
    "    url.append(submission.url)\n",
    "    selftext.append(submission.selftext)\n",
    "    name.append(submission.name)\n",
    "    num_comments.append(submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82c71121",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(990, 9)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from zipped lists. Pickle for later.\n",
    "zippedList =  list(zip(ID,title,author,created_utc,score,upvote_ratio,selftext,name,num_comments)) \n",
    "df = pd.DataFrame(zippedList,\n",
    "                     columns = ['ID','title','author','created_utc','score','upvote_ratio','selftext','name','num_comments']) \n",
    "df.to_pickle('aspergers_hot_0516.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e9d4ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>selftext</th>\n",
       "      <th>name</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>ulrn73</td>\n",
       "      <td>Nuerodiverse relationship</td>\n",
       "      <td>Moonlunar86</td>\n",
       "      <td>1.652104e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>0.60</td>\n",
       "      <td>So I’m looking for some advice/tips from anyon...</td>\n",
       "      <td>t3_ulrn73</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>uj88la</td>\n",
       "      <td>How do you avoid getting asked how you spend y...</td>\n",
       "      <td>AbdulIsGay</td>\n",
       "      <td>1.651787e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>1.00</td>\n",
       "      <td>I honestly hate being asked how I spend my tim...</td>\n",
       "      <td>t3_uj88la</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>ujp2ns</td>\n",
       "      <td>My ex husband committed suicide, I found out h...</td>\n",
       "      <td>manmadestool</td>\n",
       "      <td>1.651848e+09</td>\n",
       "      <td>282</td>\n",
       "      <td>0.92</td>\n",
       "      <td>Guys idk where to put this. Me and this man we...</td>\n",
       "      <td>t3_ujp2ns</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>uniqak</td>\n",
       "      <td>Does anyone else feel like everyone is suspici...</td>\n",
       "      <td>g59tilthegrave</td>\n",
       "      <td>1.652300e+09</td>\n",
       "      <td>126</td>\n",
       "      <td>0.98</td>\n",
       "      <td>High-functioning autist here. I was diagnosed ...</td>\n",
       "      <td>t3_uniqak</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>umlyg6</td>\n",
       "      <td>My doctor calls me delusional for no reason</td>\n",
       "      <td>Emergency_Sherbet831</td>\n",
       "      <td>1.652198e+09</td>\n",
       "      <td>5</td>\n",
       "      <td>0.73</td>\n",
       "      <td>What to do?</td>\n",
       "      <td>t3_umlyg6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>ufxeew</td>\n",
       "      <td>I might be struggling with imposter syndrome...</td>\n",
       "      <td>throwawaybreaks</td>\n",
       "      <td>1.651402e+09</td>\n",
       "      <td>9</td>\n",
       "      <td>0.85</td>\n",
       "      <td>But I'm not sure, maybe it's all in my head.</td>\n",
       "      <td>t3_ufxeew</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>un1ftu</td>\n",
       "      <td>So much fear</td>\n",
       "      <td>wadepool96</td>\n",
       "      <td>1.652243e+09</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>I have so much fear about so many things in my...</td>\n",
       "      <td>t3_un1ftu</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>ulknzb</td>\n",
       "      <td>Parroting as an attempt to join conversations.</td>\n",
       "      <td>KaseySendou</td>\n",
       "      <td>1.652077e+09</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Is it wrong to try to join in convos and try t...</td>\n",
       "      <td>t3_ulknzb</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>ul0czk</td>\n",
       "      <td>Weddings + Asperger’s</td>\n",
       "      <td>Human-Champion-6888</td>\n",
       "      <td>1.652012e+09</td>\n",
       "      <td>12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>Hi, I am married to someone recently diagnosed...</td>\n",
       "      <td>t3_ul0czk</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>ugcvsz</td>\n",
       "      <td>Was anybody misdiagnosed ?</td>\n",
       "      <td>Strong-Welder7331</td>\n",
       "      <td>1.651450e+09</td>\n",
       "      <td>2</td>\n",
       "      <td>0.76</td>\n",
       "      <td>I dont trust my diagnosis i got it when i was ...</td>\n",
       "      <td>t3_ugcvsz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                              title  \\\n",
       "480  ulrn73                          Nuerodiverse relationship   \n",
       "662  uj88la  How do you avoid getting asked how you spend y...   \n",
       "590  ujp2ns  My ex husband committed suicide, I found out h...   \n",
       "291  uniqak  Does anyone else feel like everyone is suspici...   \n",
       "408  umlyg6        My doctor calls me delusional for no reason   \n",
       "895  ufxeew    I might be struggling with imposter syndrome...   \n",
       "374  un1ftu                                       So much fear   \n",
       "500  ulknzb     Parroting as an attempt to join conversations.   \n",
       "531  ul0czk                              Weddings + Asperger’s   \n",
       "885  ugcvsz                         Was anybody misdiagnosed ?   \n",
       "\n",
       "                   author   created_utc  score  upvote_ratio  \\\n",
       "480           Moonlunar86  1.652104e+09      2          0.60   \n",
       "662            AbdulIsGay  1.651787e+09      9          1.00   \n",
       "590          manmadestool  1.651848e+09    282          0.92   \n",
       "291        g59tilthegrave  1.652300e+09    126          0.98   \n",
       "408  Emergency_Sherbet831  1.652198e+09      5          0.73   \n",
       "895       throwawaybreaks  1.651402e+09      9          0.85   \n",
       "374            wadepool96  1.652243e+09      4          1.00   \n",
       "500           KaseySendou  1.652077e+09      3          1.00   \n",
       "531   Human-Champion-6888  1.652012e+09     12          0.89   \n",
       "885     Strong-Welder7331  1.651450e+09      2          0.76   \n",
       "\n",
       "                                              selftext       name  \\\n",
       "480  So I’m looking for some advice/tips from anyon...  t3_ulrn73   \n",
       "662  I honestly hate being asked how I spend my tim...  t3_uj88la   \n",
       "590  Guys idk where to put this. Me and this man we...  t3_ujp2ns   \n",
       "291  High-functioning autist here. I was diagnosed ...  t3_uniqak   \n",
       "408                                        What to do?  t3_umlyg6   \n",
       "895       But I'm not sure, maybe it's all in my head.  t3_ufxeew   \n",
       "374  I have so much fear about so many things in my...  t3_un1ftu   \n",
       "500  Is it wrong to try to join in convos and try t...  t3_ulknzb   \n",
       "531  Hi, I am married to someone recently diagnosed...  t3_ul0czk   \n",
       "885  I dont trust my diagnosis i got it when i was ...  t3_ugcvsz   \n",
       "\n",
       "     num_comments  \n",
       "480             4  \n",
       "662             4  \n",
       "590            97  \n",
       "291            46  \n",
       "408            17  \n",
       "895            14  \n",
       "374             4  \n",
       "500             3  \n",
       "531            16  \n",
       "885             0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08eb6f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the content of user posts and run Reddit API\n",
    "# To capture as many posts as possible, the scrape is run for each of the reddit categories (hot, new, rising, top)\n",
    "title = []\n",
    "ID = []\n",
    "author = []\n",
    "created_utc = []\n",
    "score = []\n",
    "upvote_ratio = []\n",
    "url = []\n",
    "selftext = []\n",
    "name = []\n",
    "num_comments = []\n",
    "for submission in reddit.subreddit('aspergers').new(limit=1000): \n",
    "    title.append(submission.title)\n",
    "    ID.append(submission.id)\n",
    "    author.append(submission.author)\n",
    "    created_utc.append(submission.created_utc)\n",
    "    score.append(submission.score)\n",
    "    upvote_ratio.append(submission.upvote_ratio)\n",
    "    url.append(submission.url)\n",
    "    selftext.append(submission.selftext)\n",
    "    name.append(submission.name)\n",
    "    num_comments.append(submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4769e39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(997, 9)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from zipped lists. Pickle for later.\n",
    "zippedList =  list(zip(ID,title,author,created_utc,score,upvote_ratio,selftext,name,num_comments)) \n",
    "df = pd.DataFrame(zippedList,\n",
    "                     columns = ['ID','title','author','created_utc','score','upvote_ratio','selftext','name','num_comments']) \n",
    "df.to_pickle('aspergers_new_0516.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c548a8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "867d63b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the content of user posts and run Reddit API\n",
    "# To capture as many posts as possible, the scrape is run for each of the reddit categories (hot, new, rising, top)\n",
    "title = []\n",
    "ID = []\n",
    "author = []\n",
    "created_utc = []\n",
    "score = []\n",
    "upvote_ratio = []\n",
    "url = []\n",
    "selftext = []\n",
    "name = []\n",
    "num_comments = []\n",
    "for submission in reddit.subreddit('aspergers').rising(limit=1000): \n",
    "    title.append(submission.title)\n",
    "    ID.append(submission.id)\n",
    "    author.append(submission.author)\n",
    "    created_utc.append(submission.created_utc)\n",
    "    score.append(submission.score)\n",
    "    upvote_ratio.append(submission.upvote_ratio)\n",
    "    url.append(submission.url)\n",
    "    selftext.append(submission.selftext)\n",
    "    name.append(submission.name)\n",
    "    num_comments.append(submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8881ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 9)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from zipped lists. Pickle for later.\n",
    "zippedList =  list(zip(ID,title,author,created_utc,score,upvote_ratio,selftext,name,num_comments)) \n",
    "df = pd.DataFrame(zippedList,\n",
    "                     columns = ['ID','title','author','created_utc','score','upvote_ratio','selftext','name','num_comments']) \n",
    "df.to_pickle('aspergers_rising_0516.pkl')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a83c791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a1baf6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to store the content of user posts and run Reddit API\n",
    "# To capture as many posts as possible, the scrape is run for each of the reddit categories (hot, new, rising, top)\n",
    "title = []\n",
    "ID = []\n",
    "author = []\n",
    "created_utc = []\n",
    "score = []\n",
    "upvote_ratio = []\n",
    "url = []\n",
    "selftext = []\n",
    "name = []\n",
    "num_comments = []\n",
    "for submission in reddit.subreddit('aspergers').top(limit=1000): \n",
    "    title.append(submission.title)\n",
    "    ID.append(submission.id)\n",
    "    author.append(submission.author)\n",
    "    created_utc.append(submission.created_utc)\n",
    "    score.append(submission.score)\n",
    "    upvote_ratio.append(submission.upvote_ratio)\n",
    "    url.append(submission.url)\n",
    "    selftext.append(submission.selftext)\n",
    "    name.append(submission.name)\n",
    "    num_comments.append(submission.num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9b658555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 9)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe from zipped lists. Pickle for later.\n",
    "zippedList =  list(zip(ID,title,author,created_utc,score,upvote_ratio,selftext,name,num_comments)) \n",
    "df = pd.DataFrame(zippedList,\n",
    "                     columns = ['ID','title','author','created_utc','score','upvote_ratio','selftext','name','num_comments']) \n",
    "df.to_pickle('aspergers_top_0516.pkl')\n",
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
